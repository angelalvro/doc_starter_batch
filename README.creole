= Documentaci√≥n Starter Batch =

== Introducci√≥n ==

Este documento describe el flujo, configuraci√≥n y componentes involucrados en el proceso de ejecuci√≥n de un //cronjob// utilizando el starter batch.  
Se detallan los requisitos previos, las configuraciones necesarias y los enlaces relevantes a las Implementaciones de Referencia (RI) de cada componente.  
El prop√≥sito del **starter batch** es proporcionar todas las funcionalidades y la autoconfiguraci√≥n necesarias para facilitar la ejecuci√≥n de //cronjobs// definidos en la nube **OpenShift**.

Los //cronjobs// son desplegados en OpenShift con una programaci√≥n deliberadamente inv√°lida, lo que evita su ejecuci√≥n autom√°tica.  
De esta forma, existen en el cl√∫ster pero quedan a la espera de ser disparados por el framework NAUA.  
El encargado de orquestar su activaci√≥n, as√≠ como la gesti√≥n de **jobs**, es el propio framework NAUA, haciendo uso de este starter.

La ejecuci√≥n de cada //job// est√° protegida mediante un mecanismo de seguridad basado en **tokens** y **scopes**,  
lo que garantiza que solo componentes autorizados puedan iniciar procesos en el entorno de ejecuci√≥n.

== Requisitos Previos ==

* **üìÑ Cronjob en OpenShift** 
  Es necesario disponer del //cronjob// que se desea ejecutar, desplegado en el entorno de ejecuci√≥n.  
  Este componente debe incorporar el starter batch.  


* **üì° Topics Kafka** 
  Es necesario solicitar los topics para comunicaci√≥n entre los componentes.  
  La validaci√≥n y el lanzamiento del cronjob se activan mediante el consumo de eventos.  


* **üîê Client ID** 
  Cada batch debe estar asociado a un //client ID// para su trazabilidad y autenticaci√≥n.  

== Funcionalidades del Starter Batch ==

=== Funcionalidades Cronjob dentro del Starter Batch ===

El siguiente esquema ilustra la arquitectura funcional relacionada con la ejecuci√≥n de Cronjobs del **Starter Batch**.  
En √©l se representan los principales componentes involucrados as√≠ como su interacci√≥n con el sistema de eventos **Kafka**.

{{Diagrama Funcionalidad Cronjob.drawio.png|}}

==== üõ†Ô∏è JobLaunchHelper: ejecuci√≥n controlada del proceso ====

El componente {{{JobLaunchHelper}}} encapsula la l√≥gica necesaria para lanzar un //job// dentro de la arquitectura de referencia.  
Su funci√≥n principal es garantizar que la ejecuci√≥n del proceso batch est√© autorizada y parametrizada de forma segura.

* **Autorizaci√≥n basada en scopes** 
  Cada job define una lista de //scopes// necesarios para su ejecuci√≥n que llamaremos //scopes requeridos//. Estos scopes representan permisos que deben estar presentes en el entorno de ejecuci√≥n del //cronjob//, por ejemplo:

{{{
jobLaunchHelper.launchJob(  
      userJob,  
      List.of("ed-naua-manager"),  
      JobScopesOperator.AND  
); 
}}}

El helper lee los //scopes proporcionados// desde un {{{ConfigMap}}} montado en el entorno de ejecucion y verifica que estos //scopes// proporcionados por el cliente, incluyen (seg√∫n el operador {{{AND}}} o {{{OR}}}) los //scopes requeridos// del job. [Ver secci√≥n Creaci√≥n autom√°tica del ConfigMap de par√°metros de job]. Si la condici√≥n no se cumple, la ejecuci√≥n es rechazada.

* **Construcci√≥n din√°mica de par√°metros**
  El helper lee los //JobParameters// proporcionados por el cliente desde el mismo {{{ConfigMap}}},
  los transforma y los incluye como //JobParameters// al invocar el job.  
  Puedes encontrar m√°s informaci√≥n en la documentaci√≥n oficial de Spring Batch sobre el uso de los //JobParameters//:
  https://docs.spring.io/spring-batch/reference/domain.html#jobParameters  

* **Obtencion del nombre interno para el Job**
  El helper recupera el nombre del job del {{{ConfigMap}}} proporcionado por el cliente para usar ese mismo nombre como {{{jobName}}} en el proceso batch. 

* **Ejecuci√≥n controlada**
  Si la validaci√≥n es exitosa, el job se lanza mediante {{{JobLauncher}}}.  
  En caso contrario, se env√≠a un evento de rechazo y el contenedor termina con c√≥digo de error.  

Gracias a este mecanismo, se asegura que solo los procesos autorizados ‚Äîes decir, aquellos con los scopes adecuados inyectados‚Äî  
puedan activar un job en un entorno de ejecuci√≥n concreto.

==== Notificaciones del resultado de la ejecuci√≥n del job mediante eventos ====

El **starter batch** incluye un sistema de notificaciones basado en eventos Kafka que permite informar del resultado de la ejecuci√≥n de cada job.  
Estas notificaciones se publican en un topic espec√≠fico, y pueden ser de dos tipos:

* **‚úÖ Evento OK:** indica que el job se ha ejecutado correctamente.
* **‚ùå Evento KO:** se emite si el job no pudo ejecutarse por no cumplir requisitos previos, como la ausencia de scopes necesarios.

Ambos tipos de eventos utilizan como carga √∫til un objeto {{{JobResultEvent}}}  
y son publicados en un topic nombrado con el siguiente patr√≥n:

{{{
tp.<cappCode>.<cronjob>-fin-batch
}}}

El nombre del //cronjob// y el c√≥digo de la aplicaci√≥n ({{{cappCode}}}) se extraen de la configuraci√≥n del entorno,  
lo que permite construir din√°micamente el nombre del topic en tiempo de ejecuci√≥n.

* **üì§ Evento OK** 
  Generado por {{{JobCompletionNotificationService}}} cuando el job se ejecuta con √©xito.  
  Incluye el resultado y la cabecera {{{JOB_CORRELATION}}} si est√° presente.  

* **üö´ Evento KO**
  Emitido por {{{JobRejectedNotificationService}}} cuando el job no cumple las condiciones necesarias (por ejemplo, scopes insuficientes).  
  Se publica un evento {{{JobResultEvent}}} con el c√≥digo {{{MISSING_SCOPES}}}.  

Esta estrategia permite que otros componentes del sistema est√©n informados del estado de los procesos batch y puedan reaccionar en consecuencia.

Para habilitar toda esta infraestructura de gesti√≥n de eventos de forma autom√°tica,  
es necesario anotar la clase principal del servicio con {{{@EnableBatchCronjob}}}.

Esta anotaci√≥n activa la configuraci√≥n autom√°tica proporcionada por el starter batch, que incluye:

* Creaci√≥n de consumidores de eventos para activar el //cronjob//.  
* Configuraci√≥n de productores Kafka para publicar eventos de estado.  
* Registro autom√°tico de listeners y servicios de notificaci√≥n.

Gracias a esta anotaci√≥n, el servicio queda conectado al ecosistema de eventos sin necesidad de configuraci√≥n expl√≠cita adicional.

===== üì£ Job Listener =====

El {{{GissJobCompletionListener}}} es un componente clave en el ciclo de vida de un //job// dentro del starter batch.  
Implementa la interfaz {{{JobExecutionListener}}} de Spring Batch y se encarga de interceptar el evento de finalizaci√≥n  
del proceso batch para recopilar informaci√≥n detallada sobre su ejecuci√≥n.

Una vez finalizado el //job//, el listener construye un objeto {{{JobCompletionDTO}}} con la siguiente informaci√≥n:

* **Identificador del job** y **nombre** del job ejecutado.  
* **Par√°metros** con los que se lanz√≥ el proceso.  
* **Estado de salida** global del job, incluyendo c√≥digo y descripci√≥n.  
* **Metadatos temporales**: fechas de creaci√≥n, inicio, fin y √∫ltima actualizaci√≥n del proceso.
* **Detalle por pasos (steps)** : para cada uno de los steps ejecutados, se almacena su nombre, estado de salida,  
  tiempos de ejecuci√≥n y √∫ltima actualizaci√≥n.

Con toda esta informaci√≥n, el listener construye un {{{JobResultEvent}}}, que encapsula tanto los metadatos de ejecuci√≥n  
como un **c√≥digo de resultado l√≥gico** ({{{JobResultCode}}}). Este c√≥digo se deriva del //exitCode// del proceso,  
siguiendo la siguiente l√≥gica:

{{{
"COMPLETED" ‚Üí SUCCESS  
"FAILED"    ‚Üí FAILED  
"STOPPED"   ‚Üí STOPPED  
"NOOP"      ‚Üí NOOP  
Cualquier otro valor ‚Üí UNKNOWN  
}}}

Una vez generado el {{{JobResultEvent}}}, el listener lo env√≠a al topic Kafka {{{tp.<cappCode>.<cronjob>-fin-batch}}}  
a trav√©s del {{{JobCompletionNotificationService}}}.

Este listener es registrado autom√°ticamente por el starter batch si la clase principal del servicio est√° anotada con  
{{{@EnableBatchCronjob}}}.

===== ü™µ Funcionalidades de Logging en Procesos Batch =====

El starter batch incorpora una serie de **listeners de logging** preconfigurados que permiten auditar y registrar  
la ejecuci√≥n de jobs, steps y chunks.  
Estos listeners est√°n disponibles como beans Spring de forma condicional, seg√∫n las propiedades definidas en el fichero de configuraci√≥n.

Entre los principales componentes de logging, se encuentran:

* **{{{GissLoggingJobErrorListener}}}** : registra errores y resultados al finalizar un {{{Job}}}. 
* **{{{GissLoggingStepErrorListener}}}** : registra el estado y excepciones producidas en cada {{{Step}}}.  
* **{{{GissLoggingChunkErrorListener}}}** : captura errores en la ejecuci√≥n de //chunks// durante la lectura/proceso/escritura. 
* **{{{GissLoggingWriterListener}}}** : permite loguear lo que ocurre espec√≠ficamente durante la escritura de datos. 

Estos componentes est√°n activados por defecto, por lo que no es necesario configurarlos manualmente.  
Sin embargo, si se desea desactivar alguno de ellos, se puede hacer mediante la configuraci√≥n correspondiente en {{{application.yml}}}.  
Por ejemplo, para desactivar el listener de logging a nivel de {{{Job}}}:

{{{
giss:  
  batch:  
    logging-listeners:  
      job:  
        enabled: false  
}}}

Finalmente, todos estos listeners pueden ser registrados de forma autom√°tica en el job mediante el uso del  
{{{LoggingListenersPostProcessor}}}, que los asocia din√°micamente a los beans de tipo {{{Job}}} o {{{Step}}}.

===== üì° Funcionalidades de Tracing en Procesos Batch =====

Para facilitar la **observabilidad y trazabilidad** de los procesos batch, se incluye un componente de tracing  
basado en {{{BatchObservabilityBeanPostProcessor}}}, que forma parte de Spring Batch.

Este componente permite integrar autom√°ticamente el sistema de monitorizaci√≥n y trazado distribuido  
(como //OpenTelemetry// o //Micrometer//), proporcionando informaci√≥n detallada sobre la ejecuci√≥n de los jobs y steps.

Puedes encontrar m√°s informaci√≥n en la documentaci√≥n oficial de Spring Batch sobre tracing:  
https://docs.spring.io/spring-batch/reference/tracing.html

=== üöÄ Funcionalidades para el servicio de solicitud de lanzamiento dentro del Starter Batch ===

El siguiente esquema ilustra la arquitectura funcional relacionada con la solicitud de ejecuci√≥n de Cronjobs del **Starter Batch**.  
En √©l se representan los principales componentes involucrados, as√≠ como su interacci√≥n con el sistema de eventos **Kafka**.

{{Diagrama Funcionalidad Solicitud.png|}}

Como se explic√≥ anteriormente, la solicitud de ejecuci√≥n del //cronjob// se basa en una arquitectura orientada a eventos.  
Para facilitar este modelo, el Starter Batch proporciona un conjunto de componentes y mecanismos que permiten **iniciar procesos batch de forma desacoplada**, a trav√©s del consumo de eventos publicados en Kafka.

Cuando un servicio incorpora la anotaci√≥n {{{@EnableBatchSolicitante}}} y agrega las propiedades:

{{{
giss:
  batch:
    job-request-launch:
      credential:
        id: <client-id>
        secret: <client-secret>
        scope: <client-scope>
}}}

el Starter Batch configura autom√°ticamente los siguientes elementos:

* **üõ°Ô∏è Cliente OAuth2**: es el {{{ReactiveOAuth2AuthorizedClientManager}}}, que se encarga de obtener el token JWT necesario para autorizar la ejecuci√≥n del Job. Cada vez que el servicio va a emitir un evento, este cliente autoriza una solicitud del tipo {{{OAuth2AuthorizeRequest}}}, y se recupera el token que se agregar√° en las cabeceras del mensaje Kafka.

* **üì® Productor Kafka**: el componente responsable de enviar la solicitud de ejecuci√≥n es el {{{JobRequestLaunchService}}}, encargado de construir y publicar un evento de tipo {{{JobLaunchDataEvent}}} con la siguiente informaci√≥n:
  ** **cronJob**: Identificador l√≥gico del cronjob en el entorno de ejecuci√≥n.
  ** **job**: Identificador l√≥gico que se dar√° al nuevo job asociado al cronjob.
  ** **targetCappCode**: C√≥digo de aplicaci√≥n.
  ** **jobParameters**: Objeto que encapsula los par√°metros din√°micos (clave-valor) que ser√°n convertidos en {{{JobParameters}}} para el proceso batch.

  Cuando se invoca el servicio {{{JobLaunchDataEvent.sendJobRequest}}}, se realizan internamente los siguientes pasos:

  **1. Resoluci√≥n del t√≥pico destino**:  
  A partir del {{{targetCappCode}}} y el {{{cronJob}}} incluidos en el evento, se genera din√°micamente el nombre del t√≥pico al que se publicar√° el mensaje, con el siguiente patr√≥n:

{{{tp.<targetCappCode>.<cronJob>-solicitud-batch}}}

  **2. Obtenci√≥n del token de seguridad**:  
  Antes de publicar el evento, el servicio solicita al {{{ReactiveOAuth2AuthorizedClientManager}}} un token JWT usando la configuraci√≥n previamente registrada.  
  El token obtenido se a√±ade como cabecera {{{JOB_TOKEN}}} en el mensaje Kafka.

  **3. Cabecera de correlaci√≥n**:  
  Opcionalmente, si se especifican c√≥digos {{{MACA}}} de destino, estos se a√±aden en la cabecera {{{JOB_CORRELATION}}}. Si no, se toma el valor por defecto del servicio llamante, definido en su configuraci√≥n de entorno ({{{application.yaml}}}).

  **4. Publicaci√≥n del evento**:  
  El mensaje, ya completo con sus cabeceras y cuerpo serializado, se publica en el topic destino:  
  {{{tp.<targetCappCode>.<cronJob>-solicitud-batch}}}

En la siguiente secci√≥n explicaremos las funcionalidades relacionadas con los servicios consumidores del topic {{{tp.<targetCappCode>.<cronJob>-solicitud-batch}}} encargados de la validaci√≥n del token y el lanzamiento del job.

=== ‚úÖ Funcionalidades para el servicio validador/lanzador dentro del Starter Batch ===

El siguiente esquema ilustra la arquitectura funcional relacionada con la validaci√≥n y lanzamiento de Cronjobs del Starter Batch.  
En √©l se representan los principales componentes involucrados, as√≠ como su interacci√≥n con el sistema de eventos Kafka.

{{Diagrama Funcionalidad Validador_lanzador.png|}}

Para habilitar la infraestructura de validaci√≥n y lanzamiento de jobs, es necesario anotar la clase principal del servicio con {{{@EnableBatchValidadorLanzador}}}.

==== üîê Validaci√≥n del token y scopes funcionales ====

El componente {{{JobValidatorConsumerService}}} act√∫a como servicio **consumidor y validador** de eventos batch.  
Su objetivo principal es validar el token de seguridad adjunto a una solicitud de ejecuci√≥n de un job y determinar si se debe lanzar o rechazar el proceso.

El servicio escucha eventos entrantes en el topic Kafka:  
{{{tp.<targetCappCode>.<cronJob>-solicitud-batch}}}

A partir de estos mensajes, ejecuta las siguientes operaciones:

* Extrae el token JWT desde la cabecera {{{JOB_TOKEN}}}.
* Si se obtienen los scopes del token correctamente:  
  ** Publica un nuevo evento en el topic: {{{tp.<targetCappCode>.<cronJob>-inicio-batch}}}. Este nuevo mensaje incluye los scopes funcionales en la cabecera {{{JOB_SCOPES}}}.
* Si el token es inv√°lido o no contiene el claim scope:  
  ** Publica un evento de rechazo en el topic: {{{tp.<targetCappCode>.<cronJob>-fin-batch}}}. Este evento indica que el job no ser√° ejecutado debido a la falta de informaci√≥n.

==== üöÄ Lanzamiento del job batch ====

Una vez que el token y sus scopes han sido validados correctamente por el componente validador, el proceso de ejecuci√≥n batch se activa a trav√©s del servicio {{{LongRunningLaunchBatchConsumerService}}}, que se registra como consumidor Kafka del topic:  
{{{tp.<targetCappCode>.<cronJob>-inicio-batch}}}

Una vez recibidos los eventos en este topic, el componente {{{LongRunningLaunchBatchConsumerService}}} construye un nuevo job en el entorno de ejecuci√≥n utilizando la l√≥gica de negocio interna del job asociado.

==== ‚è∏Ô∏è Control del consumo mediante ACK manual ====

La configuraci√≥n del listener Kafka que consume eventos del topic {{{tp.<targetCappCode>.<cronJob>-inicio-batch}}} utiliza el modo de reconocimiento {{{MANUAL_IMMEDIATE}}}, activado mediante la propiedad:

{{{
factory.getContainerProperties().setAckMode(ContainerProperties.AckMode.MANUAL_IMMEDIATE);
}}}

Este modo tiene un prop√≥sito muy espec√≠fico en el contexto del Starter Batch:

* **Evita el consumo en paralelo** de m√∫ltiples mensajes que podr√≠an activar la misma ejecuci√≥n batch en conflicto o causar sobrecarga.
* **El listener Kafka detiene el avance del offset** hasta que se reconozca expl√≠citamente (acknowledge) el mensaje actual.
* La l√≥gica de ejecuci√≥n del job se realiza en el componente {{{LongRunningLaunchBatchConsumerService}}}. Este componente:  
  ** Inicia la ejecuci√≥n real del proceso batch.  
  ** Espera a que la ejecuci√≥n finalice (o al menos alcance un estado seguro).  
  ** Solo entonces realiza el acknowledge del mensaje Kafka.

Este enfoque garantiza que:

* El procesamiento del evento es **sincr√≥nico respecto al consumo** del topic.
* No se lanza otro job del mismo tipo mientras el anterior est√° en ejecuci√≥n.
* El sistema mantiene **consistencia y control sobre la ejecuci√≥n secuencial de jobs**, especialmente importante en procesos batch pesados.

Si la ejecuci√≥n del job falla o se interrumpe inesperadamente, el offset del mensaje **no se marca como procesado**, permitiendo la reentrega y reintento seg√∫n la estrategia de errores configurada.

==== üèóÔ∏è Creaci√≥n autom√°tica del ConfigMap de par√°metros del job ====

El servicio {{{LongRunningLaunchBatchConsumerService}}} es el encargado de la **creaci√≥n din√°mica del ConfigMap** en el entorno de ejecuci√≥n del CronJob. Este ConfigMap es esencial para **parametrizar y controlar** la ejecuci√≥n del proceso batch de forma segura y desacoplada.

El ConfigMap se genera con el siguiente patr√≥n de nombre:

{{{
<cronJob>-job-parameters-cm
}}}

Este recurso contiene la informaci√≥n clave necesaria para que el componente {{{JobLaunchHelper}}} pueda lanzar el job de forma controlada:

* **Scopes proporcionados** ({{{scopes}}}):  
  Lista de scopes funcionales que representan los permisos que han sido delegados al job. El helper los utiliza para validar si se puede autorizar la ejecuci√≥n seg√∫n los //scopes requeridos// definidos en el c√≥digo del job.

* **Par√°metros del job** ({{{parameters}}}):  
  Un conjunto de pares clave-valor que ser√°n convertidos din√°micamente en {{{JobParameters}}} para la ejecuci√≥n.

* **Nombre interno del job** ({{{jobName}}}):  
  Identificador que se usar√° para identificar el {{{Job}}} correspondiente a lanzar en Spring Batch.

Este ConfigMap se monta como recurso en el namespace calculado.

== Componentes de la Arquitectura Batch ==

=== 1. Servicio proceso Batch ===

Es el componente principal en la arquitectura batch, emcapsula el proceso batch en s√≠ mismo.  
Este servicio har√° uso del Chart Cronjob para su despliegue en el cluster OpenShift.  
El resultado de la ejecuci√≥n del Chart Cronjob ser√° un recurso Cronjob con una programaci√≥n deliberadamente inv√°lida  
y con la imagen del servicio que alberga la l√≥gica funcional del proceso batch.

==== Configuraci√≥n de dependencias ====

El servicio que ejecuta el proceso batch debe incorporar tanto el starter batch como el starter JPA del framework NAUA.  
El starter batch utiliza JPA para gestionar la persistencia del estado de ejecuci√≥n de los //jobs//.  
Esto permite mantener un registro hist√≥rico, reintentar ejecuciones fallidas desde el punto de fallo y evitar duplicidades  
si se lanza el mismo job con los mismos par√°metros.

Spring Batch guarda esta informaci√≥n en una base de datos mediante JPA, lo que facilita la trazabilidad y el control de las ejecuciones dentro de NAUA. 

{{{
<dependency>
  <groupId>es.giss.arch</groupId>
  <artifactId>giss-arch-starter-jpa</artifactId>
</dependency>
<dependency>
  <groupId>es.giss.arch</groupId>
  <artifactId>giss-arch-starter-batch</artifactId>
</dependency>
<dependency>
  <groupId>com.oracle.database.jdbc</groupId>
  <artifactId>ojdbc8</artifactId>
  <scope>runtime</scope>
</dependency>
}}}

==== üîÑ Proceso de ejecuci√≥n del batch ====

La ejecuci√≥n del proceso batch se inicia desde la clase principal del servicio, que implementa {{{CommandLineRunner}}}.  
En este punto es donde se invoca al {{{JobLaunchHelper}}} para lanzar el job correspondiente.  
Un ejemplo t√≠pico de esta configuraci√≥n es el siguiente:

{{{
@SpringBootApplication
@RequiredArgsConstructor
@EnableScheduling
@EnableBatchCronjob
public class Application implements CommandLineRunner {

    private final Job userJob;
    private final JobLaunchHelper jobLaunchHelper;

    public static void main(final String[] args) {
        SpringApplication.run(Application.class, args);
    }

    @Override
    public void run(final String... args) {
        jobLaunchHelper.launchJob(
            userJob,
            List.of("ed-naua-manager"),
            JobScopesOperator.AND
        );
    }
}
}}}

En este ejemplo, el job {{{userJob}}} es la definici√≥n del proceso batch, y se lanza √∫nicamente si se cumplen los //scopes// requeridos.  
El helper se encarga de validar los permisos, construir los par√°metros y lanzar el job si todo es correcto.

==== üß© Integraci√≥n del Listener en los procesos batch ====

Para que el {{{GissJobCompletionListener}}} act√∫e sobre los procesos batch, es necesario registrarlo expl√≠citamente en la definici√≥n del //Job//.  
Esta integraci√≥n se realiza dentro de una clase de configuraci√≥n Spring marcada con {{{@Configuration}}}, donde se define el bean del //Job//  
que encapsula la l√≥gica del proceso batch.

A continuaci√≥n, se muestra un ejemplo real de c√≥mo inyectar el listener en un proceso batch que define dos pasos ({{{step1}}} y {{{step2}}}):

{{{
@Configuration
@RequiredArgsConstructor
public class JobConfiguration {

    private final JobRepository jobRepository;
    private final GissJobCompletionListener jobCompletionListener;
    private final GissLoggingJobErrorListener gissLoggingJobErrorListener;
    private final JobLaunchHelper jobLaunchHelper;

    @Qualifier("step1")
    private final Step step1;

    @Qualifier("step2")
    private final Step step2;

    @Bean
    public Job userJob() {
        return new JobBuilder(jobLaunchHelper.getJobNameFromConfigMap(), jobRepository)
                .incrementer(new RunIdIncrementer())
                .listener(jobCompletionListener)                 // Listener que env√≠a el evento JobResultEvent
                .listener(gissLoggingJobErrorListener)           // Listener para loguear errores durante la ejecuci√≥n
                .start(step1)
                .next(step2)
                .build();
    }
}
}}}

En este ejemplo:

* **{{{jobCompletionListener}}}**: es el {{{GissJobCompletionListener}}} que se encargar√° de emitir el evento {{{JobResultEvent}}} al finalizar la ejecuci√≥n del job.  
* **{{{gissLoggingJobErrorListener}}}**: es un listener adicional que permite loguear los errores ocurridos durante la ejecuci√≥n.  
* **{{{RunIdIncrementer}}}**: garantiza que se permita la ejecuci√≥n del mismo job m√°s de una vez, usando un identificador √∫nico por ejecuci√≥n.  

Ambos listeners deben estar definidos como beans en el {{{ApplicationContext}}} para que puedan ser inyectados autom√°ticamente por Spring.  
Si est√°s utilizando el {{{@EnableBatchCronjob}}}, estos componentes son provistos autom√°ticamente por el starter batch.



=== 2. Servicio solicitud Batch ===

Es el componenete encargado de iniciar la ejecuci√≥n de un //cronjob//. Para ello, se emplea el mecanismo de emisi√≥n de eventos Kafka habilitado por el **Starter Batch**.

==== üîÑ Proceso de solicitud de lanzamiento batch ====

El servicio que ejecuta la solicitud batch debe incorporar el starter batch y para utilizar la funcionalidad de solicitud:

* Anotar la clase principal con **@EnableBatchSolicitante**.
* Configurar las credenciales OAuth2 en el fichero {{{application.yml}}} bajo {{{giss.batch.job-request-launch}}}
* Inyectar el componente {{{JobRequestLaunchService}}} y utilizar su m√©todo {{{sendJobRequest(...)}}},  
  proporcionando un objeto {{{JobLaunchDataEvent}}} que contenga:

**Par√°metros requeridos del evento:**

* Nombre del //cronjob// OpenShift.
* Nombre con el que desea identificar el //job// asociado a dicho  //cronjob//.
* Par√°metros de ejecuci√≥n.
* C√≥digo {{{capp}}} de destino ({{{targetCappCode}}}), que identifica la aplicaci√≥n batch objetivo.

Puedes consultar la inplementacion de referencia de un servicio solicitud batch: https://gitlab.pro.portal.ss/gi/naua/ris/ot_nauabsol_ri-batch-solicitante
