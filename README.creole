= Documentaci√≥n Starter Batch =

== Introducci√≥n ==

Este documento describe el flujo, configuraci√≥n y componentes involucrados en el proceso de ejecuci√≥n de un job utilizando el starter batch.  
Se detallan los requisitos previos, las configuraciones necesarias y los enlaces relevantes a las Implementaciones de Referencia (RI) de cada componente.  

**El prop√≥sito del starter batch es proporcionar todas las funcionalidades y la autoconfiguraci√≥n necesarias para facilitar la ejecuci√≥n de jobs asociados a cronjobs definidos en la nube OpenShift**.

Los cronjobs son desplegados en OpenShift con una programaci√≥n deliberadamente inv√°lida, lo que evita su ejecuci√≥n autom√°tica.  
De esta forma, existen en el cl√∫ster pero quedan a la espera de ser disparados por el framework NAUA.  
El encargado de orquestar su activaci√≥n, as√≠ como la gesti√≥n de jobs, es el propio framework NAUA, haciendo uso de este starter.

La ejecuci√≥n de cada job est√° protegida mediante un mecanismo de seguridad basado en //OAuth 2.0 client credentials flow//, lo que garantiza que solo componentes autorizados puedan iniciar procesos en el entorno de ejecuci√≥n.

== Requisitos Previos ==

* **üì° Topics Kafka** 
  Para habilitar la comunicaci√≥n entre los distintos componentes, es necesario contar con los topics de Kafka correspondientes. La validaci√≥n y el lanzamiento del job se desencadenan a trav√©s del consumo de eventos en estos topics. Los topics deben seguir la siguiente convenci√≥n de nombres y estar disponibles en el entorno de ejecuci√≥n, con permisos de lectura y escritura asignados al usuario Kafka de la aplicaci√≥n:
** {{{tp.<targetCappCode>.<cronjob>-solicitud-batch}}}
** {{{tp.<targetCappCode>.<cronjob>-inicio-batch}}}
** {{{tp.<targetCappCode>.<cronjob>-fin-batch}}}


* **üîê Client ID** 
Ser√° necesario disponer de un Client ID registrado bajo el flujo de client credentials (OAuth 2.0), como mecanismo obligatorio para securizar el lanzamiento de jobs. El scope del token obtenido mediante este flujo debe coincidir con el scope configurado para el job que se desea ejecutar. Esta correspondencia es imprescindible para que la solicitud de activaci√≥n sea considerada v√°lida por el starter batch.

== üß© Visi√≥n General del Proceso Batch: Ejecuci√≥n Orquestada por Eventos ==

El proceso batch en NAUA se estructura como una cadena de eventos asincr√≥nicos que conecta tres componentes especializados, trabajando de forma coordinada a trav√©s de **Kafka** y con control de acceso basado en **OAuth2 y scopes funcionales**.

El ciclo completo comienza con una **solicitud de ejecuci√≥n**, pasa por un **m√≥dulo validador** que asegura la autorizaci√≥n, y termina con la **ejecuci√≥n efectiva del proceso batch** encapsulado en un cronJob de OpenShift.

{{Diagrama Funcionalidad Cronjob-General.drawio.png|}}

=== üîÑ Flujo de Ejecuci√≥n y Comunicaci√≥n ===

==== Solicitud de ejecuci√≥n ==== 

El proceso se inicia desde un **servicio solicitante**, que emite un evento Kafka para solicitar la ejecuci√≥n de un job batch espec√≠fico. Este evento se publica en el topic: {{{tp.<targetCappCode>.<cronjob>-solicitud-batch}}}.

==== Validaci√≥n y autorizaci√≥n ====

Un **servicio validador/lanzador** escucha autom√°ticamente este topic. Al recibir el evento:

* Valida el token y extrae el scope.
* Si la validaci√≥n es exitosa, **emite un nuevo evento de inicio** al topic:{{{tp.<targetCappCode>.<cronjob>-inicio-batch}}}

==== Ejecuci√≥n del proceso batch ====

El **servicio batch** ‚Äîque encapsula la l√≥gica del proceso como un cronJob de OpenShift‚Äî se mantiene inactivo hasta que recibe el evento de inicio.

* Al consumir el evento desde {{{tp.<targetCappCode>.<cronjob>-inicio-batch}}}, el servicio activa la ejecuci√≥n del job mediante {{{JobLaunchHelper}}}.
* El job se ejecuta bajo control de **Spring Batch**.
* Al finalizar, el servicio emite un **evento de resultado** ({{{JobResultEvent}}}) al topic: {{{tp.<targetCappCode>.<cronjob>-fin-batch}}}

Este √∫ltimo evento permite el seguimiento del resultado de la ejecuci√≥n, completando el ciclo.

=== üîê Seguridad ===

* Todo el flujo est√° protegido mediante **OAuth2 (Client Credentials Flow)**.
* El **scope funcional** incluido en el token debe coincidir con el configurado en el job batch.

== Funcionalidades del Starter Batch ==

=== Funcionalidades Cronjob dentro del Starter Batch ===

El siguiente esquema ilustra la arquitectura funcional relacionada con la ejecuci√≥n de cronjobs del **Starter Batch**.  
En √©l se representan los principales componentes involucrados as√≠ como su interacci√≥n con el sistema de eventos **Kafka**.

{{Diagrama Funcionalidad Cronjob-Cronjob.drawio.png|}}

==== üõ†Ô∏è JobLaunchHelper: ejecuci√≥n controlada del proceso ====

El componente {{{JobLaunchHelper}}} encapsula la l√≥gica necesaria para lanzar un job dentro de la arquitectura de referencia.  
Su funci√≥n principal es garantizar que la ejecuci√≥n del proceso batch est√© autorizada y parametrizada de forma segura.

* **Autorizaci√≥n basada en scopes** 
  Cada job define una lista de //scopes// requeridos para su ejecuci√≥n. Estos scopes representan permisos que deben estar presentes en el entorno de ejecuci√≥n del cronjob, por ejemplo:

{{{
jobLaunchHelper.launchJob(  
      userJob,  
      List.of("ed-naua-manager"),  
      JobScopesOperator.AND  
); 
}}}

El helper lee los //scopes// proporcionados desde un {{{ConfigMap}}} montado en el entorno de ejecuci√≥n y verifica que estos //scopes// proporcionados por el cliente, incluyen (seg√∫n el operador {{{AND}}} o {{{OR}}}) los //scopes// requeridos del job. [Ver secci√≥n Creaci√≥n autom√°tica del ConfigMap de par√°metros de job]. Si la condici√≥n no se cumple, la ejecuci√≥n es rechazada.

* **Construcci√≥n din√°mica de par√°metros**
  El helper lee los //JobParameters// proporcionados por el cliente desde el mismo {{{ConfigMap}}},
  los transforma y los incluye como //JobParameters// al invocar el job.  
  Puedes encontrar m√°s informaci√≥n en la documentaci√≥n oficial de Spring Batch sobre el uso de los //JobParameters//:
  https://docs.spring.io/spring-batch/reference/domain.html#jobParameters  

* **Obtencion del nombre interno para el Job**
  El helper recupera el nombre del job del {{{ConfigMap}}} proporcionado por el cliente para usar ese mismo nombre como {{{jobName}}} en el proceso batch. 

* **Ejecuci√≥n controlada**
  Si la validaci√≥n es exitosa, el job se lanza mediante {{{JobLauncher}}}.  
  En caso contrario, se env√≠a un evento de rechazo y el contenedor termina con c√≥digo de error.  

Gracias a este mecanismo, se asegura que solo los procesos autorizados ‚Äîes decir, aquellos con los scopes adecuados inyectados‚Äî  
puedan activar un job en un entorno de ejecuci√≥n concreto.

==== Notificaciones del resultado de la ejecuci√≥n del job mediante eventos ====

El **starter batch** incluye un sistema de notificaciones basado en eventos Kafka que permite informar del resultado de la ejecuci√≥n de cada job.  
Estas notificaciones se publican en un topic espec√≠fico, y pueden ser de dos tipos:

* **‚úÖ Evento OK:** indica que el job se ha ejecutado correctamente.
* **‚ùå Evento KO:** se emite si el job no pudo ejecutarse por no cumplir requisitos previos, como la ausencia de scopes necesarios.

Ambos tipos de eventos utilizan como carga √∫til un objeto {{{JobResultEvent}}}  
y son publicados en un topic nombrado con el siguiente patr√≥n:

{{{
tp.<targetCappCode>.<cronjob>-fin-batch
}}}

* **üì§ Evento OK** 
  Generado por {{{JobCompletionNotificationService}}} cuando el job se ejecuta con √©xito.  

* **üö´ Evento KO**
  Emitido por {{{JobRejectedNotificationService}}} cuando el job no cumple las condiciones necesarias (por ejemplo, scopes insuficientes).  
  Se publica un evento {{{JobResultEvent}}} con el c√≥digo {{{MISSING_SCOPES}}}.  

Esta estrategia permite que otros componentes del sistema est√©n informados del estado de los procesos batch y puedan reaccionar en consecuencia.

Para habilitar toda esta infraestructura de gesti√≥n de eventos de forma autom√°tica,  
es necesario anotar la clase principal del servicio con {{{@EnableBatchCronjob}}}.

Esta anotaci√≥n activa la configuraci√≥n autom√°tica proporcionada por el starter batch, que incluye:

* Creaci√≥n de consumidores de eventos para activar el //cronjob//.  
* Configuraci√≥n de productores Kafka para publicar eventos de estado.  
* Registro autom√°tico de listeners y servicios de notificaci√≥n.

Gracias a esta anotaci√≥n, el servicio queda conectado al ecosistema de eventos sin necesidad de configuraci√≥n expl√≠cita adicional.

==== üì£ Job Listener ====

El {{{GissJobCompletionListener}}} es un componente clave en el ciclo de vida de un job dentro del starter batch.  
Implementa la interfaz {{{JobExecutionListener}}} de Spring Batch y se encarga de interceptar el evento de finalizaci√≥n  
del proceso batch para recopilar informaci√≥n detallada sobre su ejecuci√≥n.

Una vez finalizado el job, el listener construye un objeto {{{JobCompletionDTO}}} con la siguiente informaci√≥n:

* **Identificador del job** y **nombre** del job ejecutado.  
* **Par√°metros** con los que se lanz√≥ el proceso.  
* **Estado de salida** global del job, incluyendo c√≥digo y descripci√≥n.  
* **Metadatos temporales**: fechas de creaci√≥n, inicio, fin y √∫ltima actualizaci√≥n del proceso.
* **Detalle por pasos (steps)** : para cada uno de los steps ejecutados, se almacena su nombre, estado de salida,  
  tiempos de ejecuci√≥n y √∫ltima actualizaci√≥n.

Con toda esta informaci√≥n, el listener construye un {{{JobResultEvent}}}, que encapsula tanto los metadatos de ejecuci√≥n  
como un **c√≥digo de resultado l√≥gico** ({{{JobResultCode}}}). Este c√≥digo se deriva del //exitCode// del proceso,  
siguiendo la siguiente l√≥gica:

{{{
"COMPLETED" ‚Üí SUCCESS  
"FAILED"    ‚Üí FAILED  
"STOPPED"   ‚Üí STOPPED  
"NOOP"      ‚Üí NOOP  
Cualquier otro valor ‚Üí UNKNOWN  
}}}

Una vez generado el {{{JobResultEvent}}}, el listener lo env√≠a al topic Kafka {{{tp.<targetCappCode>.<cronjob>-fin-batch}}}  
a trav√©s del {{{JobCompletionNotificationService}}}.

Este listener es registrado autom√°ticamente por el starter batch si la clase principal del servicio est√° anotada con  
{{{@EnableBatchCronjob}}}.

==== ü™µ Funcionalidades de Logging en Procesos Batch ====

El starter batch incorpora una serie de **listeners de logging** preconfigurados que permiten auditar y registrar  
la ejecuci√≥n de jobs, steps y chunks.  
Estos listeners est√°n disponibles como beans Spring de forma condicional, seg√∫n las propiedades definidas en el fichero de configuraci√≥n.

Entre los principales componentes de logging, se encuentran:

* **{{{GissLoggingJobErrorListener}}}** : registra errores y resultados al finalizar un {{{Job}}}. 
* **{{{GissLoggingStepErrorListener}}}** : registra el estado y excepciones producidas en cada {{{Step}}}.  
* **{{{GissLoggingChunkErrorListener}}}** : captura errores en la ejecuci√≥n de //chunks// durante la lectura/proceso/escritura. 
* **{{{GissLoggingWriterListener}}}** : permite loguear lo que ocurre espec√≠ficamente durante la escritura de datos. 

Estos componentes est√°n activados por defecto, por lo que no es necesario configurarlos manualmente.  
Sin embargo, si se desea desactivar alguno de ellos, se puede hacer mediante la configuraci√≥n correspondiente en {{{application.yml}}}.  
Por ejemplo, para desactivar el listener de logging a nivel de {{{Job}}}:

{{{
giss:  
  batch:  
    logging-listeners:  
      job:  
        enabled: false  
}}}

Finalmente, todos estos listeners pueden ser registrados de forma autom√°tica en el job mediante el uso del  
{{{LoggingListenersPostProcessor}}}, que los asocia din√°micamente a los beans de tipo {{{Job}}} o {{{Step}}}.

==== üì° Funcionalidades de Tracing en Procesos Batch ====

Para facilitar la **observabilidad y trazabilidad** de los procesos batch, se incluye un componente de tracing  
basado en {{{BatchObservabilityBeanPostProcessor}}}, que forma parte de Spring Batch.

Este componente permite integrar autom√°ticamente el sistema de monitorizaci√≥n y trazado distribuido  
(como //OpenTelemetry// o //Micrometer//), proporcionando informaci√≥n detallada sobre la ejecuci√≥n de los jobs y steps.

Puedes encontrar m√°s informaci√≥n en la documentaci√≥n oficial de Spring Batch sobre tracing:  
https://docs.spring.io/spring-batch/reference/tracing.html

=== üöÄ Funcionalidades para el servicio de solicitud de lanzamiento dentro del Starter Batch ===

El siguiente esquema ilustra la arquitectura funcional relacionada con la solicitud de ejecuci√≥n de cronjobs del **Starter Batch**.  
En √©l se representan los principales componentes involucrados, as√≠ como su interacci√≥n con el sistema de eventos **Kafka**.

{{Diagrama Funcionalidad Cronjob-Solicitud.drawio.png|}}

Como se explic√≥ anteriormente, la solicitud de ejecuci√≥n del cronjob se basa en una arquitectura orientada a eventos.  
Para facilitar este modelo, el Starter Batch proporciona un conjunto de componentes y mecanismos que permiten **iniciar procesos batch de forma desacoplada**, a trav√©s del consumo de eventos publicados en Kafka.

Cuando un servicio incorpora la anotaci√≥n {{{@EnableBatchSolicitante}}} y agrega las propiedades:

{{{
giss:
  batch:
    job-request-launch:
      credential:
        id: <client-id>
        secret: <client-secret>
        scope: <client-scope>
}}}

el Starter Batch configura autom√°ticamente los siguientes elementos:

* **üõ°Ô∏è Cliente OAuth2**: es el {{{ReactiveOAuth2AuthorizedClientManager}}}, que se encarga de obtener el token JWT necesario para autorizar la ejecuci√≥n del Job. Cada vez que el servicio va a emitir un evento, este cliente autoriza una solicitud del tipo {{{OAuth2AuthorizeRequest}}}, y se recupera el token que se agregar√° en las cabeceras del mensaje Kafka.

* **üì® Productor Kafka**: el componente responsable de enviar la solicitud de ejecuci√≥n es el {{{JobRequestLaunchService}}}, encargado de construir y publicar un evento de tipo {{{JobLaunchDataEvent}}} con la siguiente informaci√≥n:
  ** **cronJob**: Identificador l√≥gico del cronjob en el entorno de ejecuci√≥n.
  ** **job**: Identificador l√≥gico que se dar√° al nuevo job asociado al cronjob.
  ** **targetCappCode**: C√≥digo de aplicaci√≥n.
  ** **jobParameters**: Objeto que encapsula los par√°metros din√°micos (clave-valor) que ser√°n convertidos en {{{JobParameters}}} para el proceso batch.

  Cuando se invoca el servicio {{{JobLaunchDataEvent.sendJobRequest}}}, se realizan internamente los siguientes pasos:

  **1. Resoluci√≥n del t√≥pico destino**:  
  A partir del {{{targetCappCode}}} y el {{{cronJob}}} incluidos en el evento, se genera din√°micamente el nombre del t√≥pico al que se publicar√° el mensaje, con el siguiente patr√≥n:

{{{tp.<targetCappCode>.<cronJob>-solicitud-batch}}}

  **2. Obtenci√≥n del token de seguridad**:  
  Antes de publicar el evento, el servicio solicita al {{{ReactiveOAuth2AuthorizedClientManager}}} un token JWT usando la configuraci√≥n previamente registrada.  
  El token obtenido se a√±ade como cabecera {{{JOB_TOKEN}}} en el mensaje Kafka.

  **3. Cabecera de correlaci√≥n**:  
  Opcionalmente, si se especifican c√≥digos {{{MACA}}} de destino, estos se a√±aden en la cabecera {{{JOB_CORRELATION}}}. Si no, se toma el valor por defecto del servicio llamante, definido en su configuraci√≥n de entorno ({{{application.yaml}}}).

  **4. Publicaci√≥n del evento**:  
  El mensaje, ya completo con sus cabeceras y cuerpo serializado, se publica en el topic destino:  
  {{{tp.<targetCappCode>.<cronJob>-solicitud-batch}}}

En la siguiente secci√≥n explicaremos las funcionalidades relacionadas con los servicios consumidores del topic {{{tp.<targetCappCode>.<cronJob>-solicitud-batch}}} encargados de la validaci√≥n del token y el lanzamiento del job.

üîî **Nota:** El servicio encargado de la solicitud de lanzamiento puede estar alojado en un **namespace** diferente al del **cronJob**. Por ese motivo, hablamos de {{{targetCappCode}}}.  
La resoluci√≥n del nombre del **namespace**, tanto en el cronJob como en el servicio validador/lanzador, es din√°mica y se construye a partir del valor de {{{targetCappCode}}} enviado en el evento {{{JobLaunchDataEvent}}}.

=== ‚úÖ Funcionalidades para el servicio validador/lanzador dentro del Starter Batch ===

El siguiente esquema ilustra la arquitectura funcional relacionada con la validaci√≥n y lanzamiento de cronjobs del Starter Batch.  
En √©l se representan los principales componentes involucrados, as√≠ como su interacci√≥n con el sistema de eventos Kafka.

{{Diagrama Funcionalidad Cronjob-Validador_lanzador.drawio.png|}}

Para habilitar la infraestructura de validaci√≥n y lanzamiento de jobs, es necesario anotar la clase principal del servicio con {{{@EnableBatchValidadorLanzador}}}.

==== üîê Validaci√≥n del token y scopes funcionales ====

El componente {{{JobValidatorConsumerService}}} act√∫a como servicio **consumidor y validador** de eventos batch.  
Su objetivo principal es validar el token de seguridad adjunto a una solicitud de ejecuci√≥n de un job y determinar si se debe lanzar o rechazar el proceso.

El servicio escucha eventos entrantes en el topic Kafka:  
{{{tp.<targetCappCode>.<cronJob>-solicitud-batch}}}

A partir de estos mensajes, ejecuta las siguientes operaciones:

* Extrae el token JWT desde la cabecera {{{JOB_TOKEN}}}.
* Si se obtienen los scopes del token correctamente:  
  ** Publica un nuevo evento en el topic: {{{tp.<targetCappCode>.<cronJob>-inicio-batch}}}. Este nuevo mensaje incluye los scopes funcionales en la cabecera {{{JOB_SCOPES}}}.
* Si el token es inv√°lido o no contiene el claim scope:  
  ** Publica un evento de rechazo en el topic: {{{tp.<targetCappCode>.<cronJob>-fin-batch}}}. Este evento indica que el job no ser√° ejecutado debido a la falta de informaci√≥n.

==== üöÄ Lanzamiento del job batch ====

Una vez que el token y sus scopes han sido validados correctamente por el componente validador, el proceso de ejecuci√≥n batch se activa a trav√©s del servicio {{{LongRunningLaunchBatchConsumerService}}}, que se registra como consumidor Kafka del topic:  
{{{tp.<targetCappCode>.<cronJob>-inicio-batch}}}

Una vez recibidos los eventos en este topic, el componente {{{LongRunningLaunchBatchConsumerService}}} construye un nuevo job en el entorno de ejecuci√≥n utilizando la l√≥gica de negocio interna del job asociado.

==== ‚è∏Ô∏è Control del consumo mediante ACK manual ====

La configuraci√≥n del listener Kafka que consume eventos del topic {{{tp.<targetCappCode>.<cronJob>-inicio-batch}}} utiliza el modo de reconocimiento {{{MANUAL_IMMEDIATE}}}, activado mediante la propiedad:

{{{
factory.getContainerProperties().setAckMode(ContainerProperties.AckMode.MANUAL_IMMEDIATE);
}}}

Este modo tiene un prop√≥sito muy espec√≠fico en el contexto del Starter Batch:

* **Evita el consumo en paralelo** de m√∫ltiples mensajes que podr√≠an activar la misma ejecuci√≥n batch en conflicto o causar sobrecarga.
* **El listener Kafka detiene el avance del offset** hasta que se reconozca expl√≠citamente (acknowledge) el mensaje actual.
* La l√≥gica de ejecuci√≥n del job se realiza en el componente {{{LongRunningLaunchBatchConsumerService}}}. Este componente:  
  ** Inicia la ejecuci√≥n real del proceso batch.  
  ** Espera a que la ejecuci√≥n finalice (o al menos alcance un estado seguro).  
  ** Solo entonces realiza el acknowledge del mensaje Kafka.

Este enfoque garantiza que:

* El procesamiento del evento es **sincr√≥nico respecto al consumo** del topic.
* No se lanza otro job del mismo tipo mientras el anterior est√° en ejecuci√≥n.
* El sistema mantiene **consistencia y control sobre la ejecuci√≥n secuencial de jobs**, especialmente importante en procesos batch pesados.

Si la ejecuci√≥n del job falla o se interrumpe inesperadamente, el offset del mensaje **no se marca como procesado**, permitiendo la reentrega y reintento seg√∫n la estrategia de errores configurada.

==== üèóÔ∏è Creaci√≥n autom√°tica del ConfigMap de par√°metros del job ====

El servicio {{{LongRunningLaunchBatchConsumerService}}} es el encargado de la **creaci√≥n din√°mica del ConfigMap** en el entorno de ejecuci√≥n del cronjob. Este ConfigMap es esencial para **parametrizar y controlar** la ejecuci√≥n del proceso batch de forma segura y desacoplada.

El ConfigMap se genera con el siguiente patr√≥n de nombre:

{{{
<cronJob>-job-parameters-cm
}}}

Este recurso contiene la informaci√≥n clave necesaria para que el componente {{{JobLaunchHelper}}} pueda lanzar el job de forma controlada:

* **Scopes proporcionados** ({{{scopes}}}):  
  Lista de scopes funcionales que representan los permisos que han sido delegados al job. El helper los utiliza para validar si se puede autorizar la ejecuci√≥n seg√∫n los //scopes requeridos// definidos en el c√≥digo del job.

* **Par√°metros del job** ({{{parameters}}}):  
  Un conjunto de pares clave-valor que ser√°n convertidos din√°micamente en {{{JobParameters}}} para la ejecuci√≥n.

* **Nombre interno del job** ({{{jobName}}}):  
  Identificador que se usar√° para identificar el {{{Job}}} correspondiente a lanzar en Spring Batch.

Este ConfigMap se monta como recurso en el namespace calculado.

== Componentes de la Arquitectura Batch ==

=== 1. Cronjob ===

Es el componente principal en la arquitectura batch, emcapsula el proceso batch en s√≠ mismo.  
Este servicio har√° uso del Chart cronjob para su despliegue en el cluster OpenShift.  
El resultado de la ejecuci√≥n del Chart cronjob ser√° un recurso cronjob con una programaci√≥n deliberadamente inv√°lida  
y con la imagen del servicio que alberga la l√≥gica funcional del proceso batch.

==== Configuraci√≥n de dependencias ====

El servicio que ejecuta el proceso batch debe incorporar tanto el starter batch como el starter JPA del framework NAUA.  
El starter batch utiliza JPA para gestionar la persistencia del estado de ejecuci√≥n de los //jobs//.  
Esto permite mantener un registro hist√≥rico, reintentar ejecuciones fallidas desde el punto de fallo y evitar duplicidades  
si se lanza el mismo job con los mismos par√°metros.

Spring Batch guarda esta informaci√≥n en una base de datos mediante JPA, lo que facilita la trazabilidad y el control de las ejecuciones dentro de NAUA. 

{{{
<dependency>
  <groupId>es.giss.arch</groupId>
  <artifactId>giss-arch-starter-jpa</artifactId>
</dependency>
<dependency>
  <groupId>es.giss.arch</groupId>
  <artifactId>giss-arch-starter-batch</artifactId>
</dependency>
<dependency>
  <groupId>com.oracle.database.jdbc</groupId>
  <artifactId>ojdbc8</artifactId>
  <scope>runtime</scope>
</dependency>
}}}

==== üîÑ Proceso de ejecuci√≥n del batch ====

La ejecuci√≥n del proceso batch se inicia desde la clase principal del servicio, que implementa {{{CommandLineRunner}}}.  
En este punto es donde se invoca al {{{JobLaunchHelper}}} para lanzar el job correspondiente.  
Un ejemplo t√≠pico de esta configuraci√≥n es el siguiente:

{{{
@SpringBootApplication
@RequiredArgsConstructor
@EnableScheduling
@EnableBatchCronjob
public class Application implements CommandLineRunner {

    private final Job userJob;
    private final JobLaunchHelper jobLaunchHelper;

    public static void main(final String[] args) {
        SpringApplication.run(Application.class, args);
    }

    @Override
    public void run(final String... args) {
        jobLaunchHelper.launchJob(
            userJob,
            List.of("ed-naua-manager"),
            JobScopesOperator.AND
        );
    }
}
}}}

En este ejemplo, el job {{{userJob}}} es la definici√≥n del proceso batch, y se lanza √∫nicamente si se cumplen los //scopes// requeridos.  
El helper se encarga de validar los permisos, construir los par√°metros y lanzar el job si todo es correcto.

==== üß© Integraci√≥n del Listener en los procesos batch ====

Para que el {{{GissJobCompletionListener}}} act√∫e sobre los procesos batch, es necesario registrarlo expl√≠citamente en la definici√≥n del job.  
Esta integraci√≥n se realiza dentro de una clase de configuraci√≥n Spring marcada con {{{@Configuration}}}, donde se define el bean del job  
que encapsula la l√≥gica del proceso batch.

A continuaci√≥n, se muestra un ejemplo real de c√≥mo inyectar el listener en un proceso batch que define dos pasos ({{{step1}}} y {{{step2}}}):

{{{
@Configuration
@RequiredArgsConstructor
public class JobConfiguration {

    private final JobRepository jobRepository;
    private final GissJobCompletionListener jobCompletionListener;
    private final GissLoggingJobErrorListener gissLoggingJobErrorListener;
    private final JobLaunchHelper jobLaunchHelper;

    @Qualifier("step1")
    private final Step step1;

    @Qualifier("step2")
    private final Step step2;

    @Bean
    public Job userJob() {
        return new JobBuilder(jobLaunchHelper.getJobNameFromConfigMap(), jobRepository)
                .incrementer(new RunIdIncrementer())
                .listener(jobCompletionListener)                 // Listener que env√≠a el evento JobResultEvent
                .listener(gissLoggingJobErrorListener)           // Listener para loguear errores durante la ejecuci√≥n
                .start(step1)
                .next(step2)
                .build();
    }
}
}}}

En este ejemplo:

* **{{{jobCompletionListener}}}**: es el {{{GissJobCompletionListener}}} que se encargar√° de emitir el evento {{{JobResultEvent}}} al finalizar la ejecuci√≥n del job.  
* **{{{gissLoggingJobErrorListener}}}**: es un listener adicional que permite loguear los errores ocurridos durante la ejecuci√≥n.  
* **{{{RunIdIncrementer}}}**: garantiza que se permita la ejecuci√≥n del mismo job m√°s de una vez, usando un identificador √∫nico por ejecuci√≥n.  

Ambos listeners deben estar definidos como beans en el {{{ApplicationContext}}} para que puedan ser inyectados autom√°ticamente por Spring.  
Si est√°s utilizando el {{{@EnableBatchCronjob}}}, estos componentes son provistos autom√°ticamente por el starter batch.

Puedes consultar la inplementacion de referencia de un cronjob batch: https://gitlab.pro.portal.ss/gi/naua/ris/ot_nauabcro_ri-batch-cronjob

=== 2. Servicio solicitud Batch ===

Es el componenete encargado de iniciar la ejecuci√≥n de un //cronjob//. Para ello, se emplea el mecanismo de emisi√≥n de eventos Kafka habilitado por el **Starter Batch**.

==== üîÑ Proceso de solicitud de lanzamiento batch ====

El servicio que ejecuta la solicitud batch debe incorporar el starter batch y para utilizar la funcionalidad de solicitud:

* Anotar la clase principal con **@EnableBatchSolicitante**.
* Configurar las credenciales OAuth2 en el fichero {{{application.yml}}} bajo {{{giss.batch.job-request-launch}}}
* Inyectar el componente {{{JobRequestLaunchService}}} y utilizar su m√©todo {{{sendJobRequest(...)}}},  
  proporcionando un objeto {{{JobLaunchDataEvent}}} que contenga:
** Nombre del //cronjob// OpenShift.
** Nombre con el que desea identificar el job asociado a dicho //cronjob//.
** Par√°metros de ejecuci√≥n.
** C√≥digo {{{capp}}} de destino ({{{targetCappCode}}}).

Puedes consultar la inplementacion de referencia de un servicio solicitud batch: https://gitlab.pro.portal.ss/gi/naua/ris/ot_nauabsol_ri-batch-solicitante

=== ‚úÖ 3. Servicio validador/lanzador batch ===

Este componente es el encargado de la **validaci√≥n del token**, la **extracci√≥n de los scopes funcionales** y el **lanzamiento del job**.  
Todas estas funcionalidades se activan autom√°ticamente mediante la captura de eventos en el topic {{{tp.<targetCappCode>.<cronJob>-solicitud-batch}}}

Por tanto, el servicio **no necesita implementar ninguna l√≥gica adicional**.

Para habilitar estas capacidades, el servicio debe:

* Incluir la anotaci√≥n: {{{@EnableBatchValidadorLanzador}}}
* A√±adir la siguiente configuraci√≥n m√≠nima de propiedades:

{{{
giss:
  batch:
    job-consumer-validator:
      topics: tp.<targetCappCode>.<cronJob>-solicitud-batch
      group-id: cg.<targetCappCode>.<cronJob>-solicitud-batch

    job-consumer-launch:
      topics: tp.<targetCappCode>.<cronJob>-inicio-batch
      group-id: cg.<targetCappCode>.<cronJob>-inicio-batch
}}}

Con esta configuraci√≥n, el servicio queda suscrito autom√°ticamente tanto al topic de solicitud como al de inicio, gestionando de forma transparente la validaci√≥n y ejecuci√≥n del proceso batch.

Puedes consultar la inplementacion de referencia de un servicio validador/lanzador batch: https://gitlab.pro.portal.ss/gi/naua/ris/ot_naualrcj_ri-kafka-lra-cronjob
